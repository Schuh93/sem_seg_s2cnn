{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e9a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, argparse, gzip, os, warnings, copy, time, mlflow\n",
    "import numpy as np, pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from mlflow.tracking.artifact_utils import get_artifact_uri, _get_root_uri_and_artifact_path\n",
    "from data_loader import load_train_data, load_test_data\n",
    "from models import S2ConvNet\n",
    "# from s2cnn import s2_near_identity_grid, so3_near_identity_grid, SO3Convolution, S2Convolution, so3_integrate\n",
    "from mlflow_helper import init_mlf_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318d5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLES = 10000\n",
    "TRAIN_ROT = True\n",
    "TEST_ROT = True\n",
    "\n",
    "# MAX_EPOCHS = 20\n",
    "MAX_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b2bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_ROT:\n",
    "    TRAIN_PATH = \"s2_mnist_train_dwr_\" + str(TRAIN_SAMPLES) + \".gz\"\n",
    "else:\n",
    "    raise NotImplementedError('A non-rotated training set does not exist yet.')\n",
    "    \n",
    "if TEST_ROT:\n",
    "    TEST_PATH = \"s2_mnist_cs1.gz\"\n",
    "else:\n",
    "    raise NotImplementedError('A non-rotated test set does not exist yet.')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU available: ' + torch.cuda.get_device_name())\n",
    "else:\n",
    "    raise RuntimeError('No GPU found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c776be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 10000\n",
      "Total test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_train_data(TRAIN_PATH), load_test_data(TEST_PATH)\n",
    "\n",
    "print(\"Total training examples: {}\".format(len(train_data)))\n",
    "print(\"Total test examples: {}\".format(len(test_data)))\n",
    "\n",
    "hparams = argparse.Namespace()\n",
    "\n",
    "hparams.name = 'test_model'\n",
    "hparams.train_batch_size = 32\n",
    "hparams.test_batch_size = 32\n",
    "hparams.num_workers = 0\n",
    "hparams.lr = 1e-4\n",
    "hparams.weight_decay = 0.\n",
    "\n",
    "hparams.channels = [8, 16, 16, 24, 24, 32, 64]\n",
    "hparams.bandlimit = [30, 15, 15, 8, 8, 4, 2]\n",
    "hparams.kernel_max_beta = [0.0625, 0.0625, 0.125, 0.125, 0.25, 0.25, 0.5]\n",
    "hparams.activation_fn = 'ReLU'\n",
    "hparams.batch_norm = True\n",
    "hparams.nodes = [64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09d4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ID directory created\n",
      "artifact directory created\n"
     ]
    }
   ],
   "source": [
    "tracking_uri='sqlite:///mlruns/database.db'\n",
    "tag_dict = {\"mlflow.runName\": round(time.time()),\n",
    "           \"mlflow.user\": \"dschuh\"}\n",
    "\n",
    "mlf_logger, artifact_path = init_mlf_logger(experiment_name='test_log', tracking_uri=tracking_uri, tags=tag_dict, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b784c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable / total parameters: (156882, 156882)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_function | CrossEntropyLoss | 0     \n",
      "1 | conv          | Sequential       | 149 K \n",
      "2 | dense         | Sequential       | 6 K   \n",
      "/media/data/schuh/conda_envs/envs/s2cnn_j/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0.pkl.gz... done\n",
      "load 0.pkl.gz... done\n",
      "load 1.pkl.gz... done\n",
      "load 2.pkl.gz... done\n",
      "load 1.pkl.gz... done\n",
      "load 3.pkl.gz... done\n",
      "load 4.pkl.gz... done\n",
      "load 2.pkl.gz... done\n",
      "load 14.pkl.gz... done\n",
      "load 14.pkl.gz... done\n",
      "load 15.pkl.gz... done\n",
      "load 16.pkl.gz... done\n",
      "load 15.pkl.gz... done\n",
      "load 17.pkl.gz... done\n",
      "load 16.pkl.gz... done\n",
      "load 18.pkl.gz... done\n",
      "load 19.pkl.gz... done\n",
      "load 17.pkl.gz... done\n",
      "load 20.pkl.gz... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/schuh/conda_envs/envs/s2cnn_j/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/media/data/schuh/conda_envs/envs/s2cnn_j/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e37c83554346089db6404816eac911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/schuh/conda_envs/envs/s2cnn_j/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc89674707844a9877181d2fde26dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_acc': tensor(0.8193), 'test_loss': 0.902073860168457}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.902073860168457, 'test_acc': 0.8192999958992004}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = S2ConvNet(hparams, train_data, test_data)\n",
    "mlf_logger.experiment.set_tag(run_id=mlf_logger.run_id, key=\"model\", value=model.__class__.__name__)\n",
    "\n",
    "print(f\"Number of trainable / total parameters: {model.count_trainable_parameters(), model.count_parameters()}\")\n",
    "\n",
    "monitor = 'val_acc'\n",
    "mode = 'max'\n",
    "early_stopping = pl.callbacks.EarlyStopping(monitor=monitor, min_delta=0., patience=10, mode=mode)\n",
    "checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(filepath=artifact_path, monitor=monitor, mode=mode)\n",
    "\n",
    "log_dict = {'es_min_delta': early_stopping.min_delta,\n",
    "           'es_mode': early_stopping.mode,\n",
    "           'es_monitor': early_stopping.monitor,\n",
    "           'es_patience': early_stopping.patience,\n",
    "           'max_epochs': MAX_EPOCHS,\n",
    "           'train_samples': len(train_data),\n",
    "           'train_rot': TRAIN_ROT,\n",
    "           'test_rot': TEST_ROT}\n",
    "\n",
    "mlf_logger.log_hyperparams(log_dict)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=MAX_EPOCHS, logger=mlf_logger, early_stop_callback=early_stopping, checkpoint_callback=checkpoint)\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "mlf_logger.experiment.log_param(run_id=mlf_logger.run_id, key='es_stopped_epoch', value=early_stopping.stopped_epoch)\n",
    "\n",
    "best_model = torch.load(checkpoint.best_model_path)\n",
    "model.load_state_dict(best_model['state_dict'])\n",
    "model.eval()\n",
    "test_results = trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test_results.pickle'\n",
    "\n",
    "if os.path.isfile(os.path.join(artifact_path, filename)):\n",
    "    filename = str(time.time()) + filename\n",
    "    print('File already existed, timestamp was prepended to filename.')\n",
    "    \n",
    "with open(os.path.join(artifact_path, filename), 'wb') as file:\n",
    "    pickle.dump(test_results, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
