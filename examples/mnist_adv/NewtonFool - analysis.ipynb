{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0de93b3",
   "metadata": {},
   "source": [
    "# NewtonFool Attack\n",
    "\n",
    "The idea of the attack is to decrease the largest softmax output of the original prediction. In order to do this, they linearize said output and say that the want to decrease the current output $p_i$ to the output of the next step $p_{i+1}$ with the smallest step possible - smallest according to the $L_2$ norm. The first output $p_0$ is given by the network. Every following desired output is yielded by the minimum of a proposal from the gradient and the desire to get $p$ below $1/C$, where $C$ denotes the total number of classes. <br>\n",
    "\n",
    "The issue with changing everything to the $L_\\infty$ norm is that it is quite tricky to get a minimal norm solution according to the $L_\\infty$ norm, since it does not exist in closed form.\n",
    "\n",
    "What I can try, though, is to let the steps be chosen by the $L_2$ norm and use the $L_\\infty$ norm for the rest, i.e. the requirement for a small step (in combination with $\\eta$) and the clipping. (works the worst)\n",
    "\n",
    "Alternatively, I can only do the clipping according to the $L_\\infty$ norm and let the rest run with the $L_2$ norm.\n",
    "\n",
    "Nothing works satisfactorily and the attack is a bit weird with the $L_\\infty$ norm, so I'm going to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ac46c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eagerpy as ep\n",
    "from typing import Union, Tuple, Any, Optional\n",
    "from foolbox.models import Model\n",
    "from foolbox.criteria import Misclassification\n",
    "from foolbox.distances import l2, linf\n",
    "from foolbox.devutils import atleast_kd, flatten\n",
    "from foolbox.attacks.base import MinimizationAttack, get_criterion, T, raise_if_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a559a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import doesn't work, so I copied the source code of the function here\n",
    "def verify_input_bounds(input: ep.Tensor, model: Model) -> None:\n",
    "    # verify that input to the attack lies within model's input bounds\n",
    "    assert input.min().item() >= model.bounds.lower\n",
    "    assert input.max().item() <= model.bounds.upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f0cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, argparse, os, warnings, copy, time, mlflow\n",
    "import numpy as np, pytorch_lightning as pl, matplotlib.pyplot as plt, eagerpy as ep\n",
    "from models import ConvNet, CConvNet\n",
    "from data_loader import load_test_data, load_train_data\n",
    "from foolbox import PyTorchModel\n",
    "from tqdm.notebook import tqdm\n",
    "from attack_helper import batched_predictions, batched_predictions, batched_logits\n",
    "from mlflow.tracking.artifact_utils import get_artifact_uri\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80af50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 1697206030\n",
    "tracking_uri = 'sqlite:///mlruns/database.db'\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "df=mlflow.search_runs(experiment_names=['model_training'])\n",
    "run_id=df[df['tags.mlflow.runName']==str(run_name)]['run_id'].values[0]\n",
    "artifact_path = get_artifact_uri(run_id=run_id, tracking_uri=tracking_uri)\n",
    "dirs=os.listdir(artifact_path)\n",
    "\n",
    "for s in dirs:\n",
    "    if s.find('.ckpt') >= 0:\n",
    "        checkpoint = s\n",
    "        break\n",
    "\n",
    "checkpoint_path = os.path.join(artifact_path, checkpoint)\n",
    "\n",
    "best_model = torch.load(checkpoint_path)\n",
    "hparams = argparse.Namespace(**best_model['hyper_parameters'])\n",
    "if df[df['tags.mlflow.runName']==str(run_name)]['tags.model'].values[0] == 'ConvNet':\n",
    "    model = ConvNet(hparams, None, None).eval()\n",
    "elif df[df['tags.mlflow.runName']==str(run_name)]['tags.model'].values[0] == 'CConvNet':\n",
    "    model = CConvNet(hparams, None, None).eval()\n",
    "else:\n",
    "    raise NotImplementedError(f\"Model has to be 'ConvNet' or 'CConvNet'. Got {df[df['tags.mlflow.runName']==str(run_name)]['tags.model'].values[0]}.\")\n",
    "model.load_state_dict(best_model['state_dict'])\n",
    "\n",
    "test_rot = eval(df[df['tags.mlflow.runName']==str(run_name)]['params.test_rot'].values[0])\n",
    "\n",
    "if df[df['tags.mlflow.runName']==str(run_name)]['params.flat'].values[0] is None:\n",
    "    flat = False\n",
    "else:\n",
    "    flat = eval(df[df['tags.mlflow.runName']==str(run_name)]['params.flat'].values[0])\n",
    "\n",
    "if flat:\n",
    "    padded_img_size = eval(df[df['tags.mlflow.runName']==str(run_name)]['params.padded_img_size'].values[0])\n",
    "\n",
    "    if test_rot:\n",
    "        TEST_PATH = \"flat_mnist_test_aug_\" + str(padded_img_size[0]) + \"x\" + str(padded_img_size[1]) + \".gz\"\n",
    "    else:\n",
    "        TEST_PATH = \"flat_mnist_test_\" + str(padded_img_size[0]) + \"x\" + str(padded_img_size[1]) + \".gz\"\n",
    "\n",
    "    test_data = load_train_data(TEST_PATH)\n",
    "\n",
    "else:    \n",
    "    if test_rot:\n",
    "        TEST_PATH = \"s2_mnist_cs1.gz\"\n",
    "        test_data = load_test_data(TEST_PATH)\n",
    "    else:\n",
    "        TEST_PATH = \"s2_mnist_test_sphere_center.gz\"\n",
    "        test_data = load_train_data(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1fb906fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewtonFoolAttack(MinimizationAttack):\n",
    "    \"\"\"Implementation of the NewtonFool Attack. [#Jang17]_\n",
    "\n",
    "    Args:\n",
    "        steps : Number of update steps to perform.\n",
    "        step_size : Size of each update step.\n",
    "\n",
    "    References:\n",
    "        .. [#Jang17] Uyeong Jang et al., \"Objective Metrics and Gradient Descent\n",
    "            Algorithms for Adversarial Examples in Machine Learning\",\n",
    "            https://dl.acm.org/citation.cfm?id=3134635\n",
    "    \"\"\"\n",
    "\n",
    "    distance = l2\n",
    "\n",
    "    def __init__(self, steps: int = 100, stepsize: float = 0.01):\n",
    "        self.steps = steps\n",
    "        self.stepsize = stepsize\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        model: Model,\n",
    "        inputs: T,\n",
    "        criterion: Union[Misclassification, T],\n",
    "        *,\n",
    "        early_stop: Optional[float] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> T:\n",
    "        raise_if_kwargs(kwargs)\n",
    "        x, restore_type = ep.astensor_(inputs)\n",
    "        criterion_ = get_criterion(criterion)\n",
    "        del inputs, criterion, kwargs\n",
    "\n",
    "        verify_input_bounds(x, model)\n",
    "\n",
    "        N = len(x)\n",
    "\n",
    "        if isinstance(criterion_, Misclassification):\n",
    "            classes = criterion_.labels\n",
    "        else:\n",
    "            raise ValueError(\"unsupported criterion\")\n",
    "\n",
    "        if classes.shape != (N,):\n",
    "            raise ValueError(\n",
    "                f\"expected labels to have shape ({N},), got {classes.shape}\"\n",
    "            )\n",
    "\n",
    "        min_, max_ = model.bounds\n",
    "\n",
    "        x_l2_norm = flatten(x.square()).sum(1).sqrt()\n",
    "        \n",
    "#         print(x_l2_norm.raw)\n",
    "\n",
    "        def loss_fun(x: ep.Tensor) -> Tuple[ep.Tensor, Tuple[ep.Tensor, ep.Tensor]]:\n",
    "            logits = model(x)\n",
    "            scores = ep.softmax(logits)\n",
    "            pred_scores = scores[range(N), classes]\n",
    "            loss = pred_scores.sum()\n",
    "            return loss, (scores, pred_scores)\n",
    "\n",
    "        for i in range(self.steps):\n",
    "            # (1) get the scores and gradients\n",
    "            _, (scores, pred_scores), gradients = ep.value_aux_and_grad(loss_fun, x)\n",
    "\n",
    "            pred = scores.argmax(-1)\n",
    "            num_classes = scores.shape[-1]\n",
    "            \n",
    "#             print('scores: ', scores.raw[0], '\\npred_scores: ', pred_scores.raw[0], '\\ngradients:', gradients.raw[0])\n",
    "\n",
    "            # (2) calculate gradient norm\n",
    "            gradients_l2_norm = flatten(gradients.square()).sum(1).sqrt()\n",
    "\n",
    "            # (3) calculate delta\n",
    "            a = self.stepsize * x_l2_norm * gradients_l2_norm\n",
    "            b = pred_scores - 1.0 / num_classes\n",
    "\n",
    "            delta = ep.minimum(a, b)\n",
    "            \n",
    "#             print('delta = ', delta)\n",
    "\n",
    "            # (4) stop the attack if an adversarial example has been found\n",
    "            # this is not described in the paper but otherwise once the prob. drops\n",
    "            # below chance level the likelihood is not decreased but increased\n",
    "            is_not_adversarial = (pred == classes).float32()\n",
    "            delta *= is_not_adversarial\n",
    "            \n",
    "#             print('delta = ', delta)\n",
    "\n",
    "#             print('gradients squared = ', gradients_l2_norm.square())\n",
    "            \n",
    "            # (5) calculate & apply current perturbation\n",
    "            a = atleast_kd(delta / gradients_l2_norm.square(), gradients.ndim)\n",
    "            \n",
    "#             print('a[0] = ', a[0,0,0,0])\n",
    "            \n",
    "            x -= a * gradients\n",
    "            \n",
    "#             print('x[0] = ', x[0,0])\n",
    "\n",
    "            x = ep.clip(x, min_, max_)\n",
    "            \n",
    "#             print('xc[0] = ', x[0,0])\n",
    "            \n",
    "#             print('\\n\\nEND\\n\\n')\n",
    "\n",
    "        return restore_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0cd2110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class LinfNewtonFoolAttack(MinimizationAttack):\n",
    "\n",
    "    distance = linf\n",
    "\n",
    "    def __init__(self, steps: int = 100, stepsize: float = 0.01):\n",
    "        self.steps = steps\n",
    "        self.stepsize = stepsize\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        model: Model,\n",
    "        inputs: T,\n",
    "        criterion: Union[Misclassification, T],\n",
    "        *,\n",
    "        early_stop: Optional[float] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> T:\n",
    "        raise_if_kwargs(kwargs)\n",
    "        x, restore_type = ep.astensor_(inputs)\n",
    "        criterion_ = get_criterion(criterion)\n",
    "        del inputs, criterion, kwargs\n",
    "\n",
    "        verify_input_bounds(x, model)\n",
    "\n",
    "        N = len(x)\n",
    "\n",
    "        if isinstance(criterion_, Misclassification):\n",
    "            classes = criterion_.labels\n",
    "        else:\n",
    "            raise ValueError(\"unsupported criterion\")\n",
    "\n",
    "        if classes.shape != (N,):\n",
    "            raise ValueError(\n",
    "                f\"expected labels to have shape ({N},), got {classes.shape}\"\n",
    "            )\n",
    "\n",
    "        min_, max_ = model.bounds\n",
    "\n",
    "        x_l2_norm = flatten(x.square()).sum(1).sqrt()\n",
    "\n",
    "        def loss_fun(x: ep.Tensor) -> Tuple[ep.Tensor, Tuple[ep.Tensor, ep.Tensor]]:\n",
    "            logits = model(x)\n",
    "            scores = ep.softmax(logits)\n",
    "            pred_scores = scores[range(N), classes]\n",
    "            loss = pred_scores.sum()\n",
    "            return loss, (scores, pred_scores)\n",
    "\n",
    "        for i in range(self.steps):\n",
    "            # (1) get the scores and gradients\n",
    "            _, (scores, pred_scores), gradients = ep.value_aux_and_grad(loss_fun, x)\n",
    "\n",
    "            pred = scores.argmax(-1)\n",
    "            num_classes = scores.shape[-1]\n",
    "\n",
    "            # (2) calculate gradient norm\n",
    "            gradients_l2_norm = flatten(gradients.square()).sum(1).sqrt()\n",
    "\n",
    "            # (3) calculate delta\n",
    "            a = self.stepsize * x_l2_norm * gradients_l2_norm\n",
    "            b = pred_scores - 1.0 / num_classes\n",
    "\n",
    "            delta = ep.minimum(a, b)\n",
    "            \n",
    "            # (4) stop the attack if an adversarial example has been found\n",
    "            # this is not described in the paper but otherwise once the prob. drops\n",
    "            # below chance level the likelihood is not decreased but increased\n",
    "            is_not_adversarial = (pred == classes).float32()\n",
    "            delta *= is_not_adversarial\n",
    "            \n",
    "            # (5) calculate & apply current perturbation\n",
    "            a = atleast_kd(delta / gradients_l2_norm.square(), gradients.ndim)\n",
    "            \n",
    "            x -= a * gradients\n",
    "\n",
    "            x = ep.clip(x, min_, max_)\n",
    "\n",
    "        return restore_type(x)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "20fa0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This attack does not exist like that. The paper assumes the norm to be L_2.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"class LinfNewtonFoolAttack(MinimizationAttack):\n",
    "    \n",
    "    distance = linf\n",
    "    \n",
    "    def __init__(self, steps: int = 100, stepsize: float = 0.01):\n",
    "        self.steps = steps\n",
    "        self.stepsize = stepsize\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        model: Model,\n",
    "        inputs: T,\n",
    "        criterion: Union[Misclassification, T],\n",
    "        *,\n",
    "        early_stop: Optional[float] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> T:\n",
    "        raise_if_kwargs(kwargs)\n",
    "        x, restore_type = ep.astensor_(inputs)\n",
    "        criterion_ = get_criterion(criterion)\n",
    "        del inputs, criterion, kwargs\n",
    "\n",
    "        verify_input_bounds(x, model)\n",
    "\n",
    "        N = len(x)\n",
    "\n",
    "        if isinstance(criterion_, Misclassification):\n",
    "            classes = criterion_.labels\n",
    "        else:\n",
    "            raise ValueError(\"unsupported criterion\")\n",
    "\n",
    "        if classes.shape != (N,):\n",
    "            raise ValueError(\n",
    "                f\"expected labels to have shape ({N},), got {classes.shape}\"\n",
    "            )\n",
    "\n",
    "        min_, max_ = model.bounds\n",
    "        \n",
    "        x_linf_norm = flatten(x.abs()).max(1)\n",
    "\n",
    "        def loss_fun(x: ep.Tensor) -> Tuple[ep.Tensor, Tuple[ep.Tensor, ep.Tensor]]:\n",
    "            logits = model(x)\n",
    "            scores = ep.softmax(logits)\n",
    "            pred_scores = scores[range(N), classes]\n",
    "            loss = pred_scores.sum()\n",
    "            return loss, (scores, pred_scores)\n",
    "        \n",
    "        for i in range(self.steps):\n",
    "            # (1) get the scores and gradients\n",
    "            _, (scores, pred_scores), gradients = ep.value_aux_and_grad(loss_fun, x)\n",
    "\n",
    "            pred = scores.argmax(-1)\n",
    "            num_classes = scores.shape[-1]\n",
    "            \n",
    "            # (2) calculate gradient norm\n",
    "            gradients_linf_norm = flatten(gradients.abs()).max(1)\n",
    "            \n",
    "            # (3) calculate delta\n",
    "            a = self.stepsize * x_linf_norm * gradients_linf_norm\n",
    "            b = pred_scores - 1.0 / num_classes\n",
    "\n",
    "            delta = ep.minimum(a, b)\n",
    "            \n",
    "            # (4) stop the attack if an adversarial example has been found\n",
    "            # this is not described in the paper but otherwise once the prob. drops\n",
    "            # below chance level the likelihood is not decreased but increased\n",
    "            is_not_adversarial = (pred == classes).float32()\n",
    "            delta *= is_not_adversarial\n",
    "            \n",
    "            # (5) calculate & apply current perturbation\n",
    "            a = atleast_kd(delta / gradients_linf_norm.square(), gradients.ndim)\n",
    "            x -= a * gradients\n",
    "            x = ep.clip(x, min_, max_)\n",
    "            \n",
    "        return restore_type(x)\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cb925eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinfNewtonFoolAttack(MinimizationAttack):\n",
    "\n",
    "    distance = linf\n",
    "\n",
    "    def __init__(self, steps: int = 100, stepsize: float = 0.01):\n",
    "        self.steps = steps\n",
    "        self.stepsize = stepsize\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        model: Model,\n",
    "        inputs: T,\n",
    "        criterion: Union[Misclassification, T],\n",
    "        *,\n",
    "        early_stop: Optional[float] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> T:\n",
    "        raise_if_kwargs(kwargs)\n",
    "        x, restore_type = ep.astensor_(inputs)\n",
    "        criterion_ = get_criterion(criterion)\n",
    "        del inputs, criterion, kwargs\n",
    "\n",
    "        verify_input_bounds(x, model)\n",
    "\n",
    "        N = len(x)\n",
    "\n",
    "        if isinstance(criterion_, Misclassification):\n",
    "            classes = criterion_.labels\n",
    "        else:\n",
    "            raise ValueError(\"unsupported criterion\")\n",
    "\n",
    "        if classes.shape != (N,):\n",
    "            raise ValueError(\n",
    "                f\"expected labels to have shape ({N},), got {classes.shape}\"\n",
    "            )\n",
    "\n",
    "        min_, max_ = model.bounds\n",
    "\n",
    "        x_linf_norm = flatten(x.abs()).max(1)\n",
    "\n",
    "        def loss_fun(x: ep.Tensor) -> Tuple[ep.Tensor, Tuple[ep.Tensor, ep.Tensor]]:\n",
    "            logits = model(x)\n",
    "            scores = ep.softmax(logits)\n",
    "            pred_scores = scores[range(N), classes]\n",
    "            loss = pred_scores.sum()\n",
    "            return loss, (scores, pred_scores)\n",
    "\n",
    "        for i in range(self.steps):\n",
    "            # (1) get the scores and gradients\n",
    "            _, (scores, pred_scores), gradients = ep.value_aux_and_grad(loss_fun, x)\n",
    "\n",
    "            pred = scores.argmax(-1)\n",
    "            num_classes = scores.shape[-1]\n",
    "\n",
    "            # (2) calculate gradient norm\n",
    "            gradients_l2_norm = flatten(gradients.square()).sum(1).sqrt()\n",
    "            gradients_linf_norm = flatten(gradients.abs()).max(1)\n",
    "\n",
    "            # (3) calculate delta\n",
    "            a = self.stepsize * x_linf_norm * gradients_linf_norm\n",
    "            b = pred_scores - 1.0 / num_classes\n",
    "\n",
    "            delta = ep.minimum(a, b)\n",
    "            \n",
    "            # (4) stop the attack if an adversarial example has been found\n",
    "            # this is not described in the paper but otherwise once the prob. drops\n",
    "            # below chance level the likelihood is not decreased but increased\n",
    "            is_not_adversarial = (pred == classes).float32()\n",
    "            delta *= is_not_adversarial\n",
    "            \n",
    "            # (5) calculate & apply current perturbation\n",
    "            a = atleast_kd(delta / gradients_l2_norm.square(), gradients.ndim)\n",
    "            \n",
    "            x -= a * gradients\n",
    "\n",
    "            x = ep.clip(x, min_, max_)\n",
    "\n",
    "        return restore_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "41f614b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = 10000\n",
    "bs = 100\n",
    "total = 100\n",
    "\n",
    "images = test_data[:total][0]\n",
    "labels = test_data[:total][1]\n",
    "\n",
    "fmodel = PyTorchModel(model, bounds=(0, 255))\n",
    "\n",
    "epsilons = [0, 0.5, 2.5, 5, 7.5, 10, 14, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b7b33bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39116033d04a4299809fb2e0beb6a611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_pred = batched_predictions(model, images, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c81a2735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0300, 0.0500, 0.0500, 0.0700, 0.1000, 0.1300, 0.3500],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "attack = LinfNewtonFoolAttack(steps=300, stepsize=0.04)\n",
    "\n",
    "raw_advs, clipped_advs, success = attack(fmodel, images.cuda(), clean_pred[:100].cuda(), epsilons=epsilons)\n",
    "\n",
    "success_rate = ep.astensor(success).float32().mean(axis=-1).raw\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "631c64d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 10 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1200, 0.1200, 0.1200],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0900, 0.1300, 0.2400, 0.4800],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1300, 0.2300, 0.4500],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0900, 0.1400, 0.2300, 0.4500],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0900, 0.1300, 0.2300, 0.4500],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0900, 0.1300, 0.2400, 0.4500],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1400, 0.2400, 0.4400],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.01 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1300, 0.2400, 0.4700],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2300, 0.4000],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2400, 0.5500],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2400, 0.5500],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2500, 0.5400],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2500, 0.5400],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2600, 0.5500],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2400, 0.5400],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.02 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0800, 0.0800, 0.1200, 0.2400, 0.5400],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3200, 0.7100],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3300, 0.7100],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3300, 0.7000],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3300, 0.7000],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3200, 0.7000],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3200, 0.7100],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3200, 0.7100],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.05 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0900, 0.1000, 0.1700, 0.3300, 0.7100],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.1 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1400, 0.1800, 0.4100, 0.7200],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.25 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0800, 0.1800, 0.4200, 0.7900],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.4 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1700, 0.3100, 0.6300],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.5 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5600],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 30 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.6 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2900, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.75 \n",
      " success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1100, 0.1800, 0.2800, 0.5100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# for stepsize in [0.01, 0.02, 0.05, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75]:\n",
    "#     for steps in [10, 30, 50, 70, 100, 200, 300, 500]:\n",
    "#         attack = LinfNewtonFoolAttack(steps=steps, stepsize=stepsize)\n",
    "\n",
    "#         raw_advs, clipped_advs, success = attack(fmodel, images.cuda(), clean_pred[:100].cuda(), epsilons=epsilons)\n",
    "\n",
    "#         success_rate = ep.astensor(success).float32().mean(axis=-1).raw\n",
    "#         print('steps:', steps, 'stepsize:', stepsize, '\\nsuccess_rate:', success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "09b94ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 10 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2300, 0.2900],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2700, 0.4900],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2700, 0.5000],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2600, 0.4900],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2700, 0.5000],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2600, 0.5000],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2600, 0.5000],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.01 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.1000, 0.1300, 0.2600, 0.5000],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2200, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.6000],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.5900],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.6000],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.5900],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.5900],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.6000],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.02 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1300, 0.2300, 0.6100],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.03 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.0900, 0.1300, 0.2600, 0.5700],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.04 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0500, 0.0600, 0.0700, 0.1500, 0.2300, 0.5800],\n",
      "       device='cuda:0')\n",
      "steps: 10 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 30 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 50 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 70 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 100 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 200 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 300 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n",
      "steps: 500 stepsize: 0.05 \n",
      "success_rate: tensor([0.0000, 0.0000, 0.0400, 0.0600, 0.0700, 0.1000, 0.1500, 0.2500, 0.6200],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for stepsize in [0.01, 0.02, 0.03, 0.04, 0.05]:\n",
    "    for steps in [10, 30, 50, 70, 100, 200, 300, 500]:\n",
    "        attack = LinfNewtonFoolAttack(steps=steps, stepsize=stepsize)\n",
    "\n",
    "        raw_advs, clipped_advs, success = attack(fmodel, images.cuda(), clean_pred[:100].cuda(), epsilons=epsilons)\n",
    "\n",
    "        success_rate = ep.astensor(success).float32().mean(axis=-1).raw\n",
    "        print('steps:', steps, 'stepsize:', stepsize, '\\nsuccess_rate:', success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f25b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
